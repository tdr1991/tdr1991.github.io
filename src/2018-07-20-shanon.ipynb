{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 信息量\n",
    "$$h(x) = -log_2 p(x)$$\n",
    "表示一个事件给出的信息多少，概率越小，信息量越大，包含的不确定性越高\n",
    "## 信息熵\n",
    "表示**信息量的期望**，即均值\n",
    "$$H(X) = -\\sum_{x \\in X}p(x) log_2 p(x)$$\n",
    "## 交叉熵\n",
    "关于样本集的两个概率分布p和q，其中p为真实分布，q为非真实分布。使用非真实分布q分布编码样本，则是基于分布q的信息量的期望，称之为交叉熵。\n",
    "$$CEH(p,q) =-\\sum_{x \\in X}p(x) log_2 q(x)$$\n",
    "## 相对熵\n",
    "交叉熵与信息熵的差值称为**相对熵**，又称**KL散度**\n",
    "$$ KL(p,q) = CEH(p,q) - H(p) = \\sum_{k=1}^{N} p_k log_2 \\frac{p_k}{q_k} $$\n",
    "## 机器学习交叉熵\n",
    "y为真实分布，q(x)由数据计算的概率分布。机器学习的目的是要q(x)尽可能逼近y，使得相对熵接近最小值0。由于真实分布式固定的，相对熵的后半部分H(p)就成了一个常数。那么优化相对熵最小，相当于优化交叉熵最小，也等效于求最大似然估计。 \n",
    "y：1对于类1,0对于类2,此时的优化函数为可能为  \n",
    "$$ L(\\theta) = q_\\theta(x_1) (1 - q_\\theta(x_2)) \\cdots q_\\theta(x_n) $$\n",
    "$$ arg max_\\theta L = arg min_\\theta -ln L $$\n",
    "实际操作时取e的对数\n",
    "$$ -ln L(\\theta) = -\\sum_i y_i ln q_\\theta(x_i) + (1 - y_i) ln (1 - q_\\theta(x_i)) $$\n",
    "### 交叉熵求导\n",
    "$$ \\frac{\\partial -ln L(\\theta)}{\\partial \\theta} = -\\sum_i y_i \\frac{\\partial ln q_\\theta(x_i)}{\\partial \\theta} + (1 - y_i) \\frac{\\partial ln (1 - q_\\theta(x_i))}{\\partial \\theta} $$\n",
    "$$ q_\\theta (x) = \\sigma (z)$$\n",
    "$$ \\frac{\\partial \\sigma (z)}{\\partial z} = \\sigma (z) (1 - \\sigma (z)) $$\n",
    "$$ z = \\theta x $$\n",
    "$$ \\frac{\\partial z}{\\partial \\theta} = x $$\n",
    "$$ \\frac{\\partial ln q_\\theta(x_i)}{\\partial z} = \\frac{\\partial ln \\sigma (z)}{\\partial z} = \\frac{1}{\\sigma (z)} \\frac{\\partial \\sigma (z)}{\\partial z} = (1 - \\sigma (z)) $$\n",
    "$$\\frac{\\partial ln q_\\theta(x_i)}{\\partial \\theta} = \\frac{\\partial ln q_\\theta(x_i)}{\\partial z} \\frac{\\partial z}{\\partial \\theta} = (1 - q_\\theta(x_i)) x_i $$\n",
    "同理可得：  \n",
    "$$ \\frac{\\partial ln (1 - q_\\theta(x_i))}{\\partial \\theta} = - q_\\theta(x_i) x_i $$\n",
    "$$ \\frac{\\partial -ln L(\\theta)}{\\partial \\theta} =  -\\sum_i (y_i - q_\\theta(x_i)) x_i $$\n",
    "$(y_i - q_\\theta(x_i))$该项越大，权重更新时也越大"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  },
  "toc": {
   "colors": {
    "hover_highlight": "#DAA520",
    "navigate_num": "#000000",
    "navigate_text": "#333333",
    "running_highlight": "#FF0000",
    "selected_highlight": "#FFD700",
    "sidebar_border": "#EEEEEE",
    "wrapper_background": "#FFFFFF"
   },
   "moveMenuLeft": true,
   "nav_menu": {
    "height": "11px",
    "width": "252px"
   },
   "navigate_menu": true,
   "number_sections": true,
   "sideBar": true,
   "threshold": 4,
   "toc_cell": false,
   "toc_section_display": "block",
   "toc_window_display": false,
   "widenNotebook": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
